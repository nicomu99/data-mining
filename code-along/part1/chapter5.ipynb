{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Simple Gradient Descent",
   "id": "43ee2e9bed851d63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:36:21.148694Z",
     "start_time": "2025-07-15T09:36:21.144747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)"
   ],
   "id": "11ed1b39abc98855",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:35:57.964010Z",
     "start_time": "2025-07-15T09:35:57.960202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]    # In Celsius\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]    # No units\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)"
   ],
   "id": "15175bd2acedc0b1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:37:07.389232Z",
     "start_time": "2025-07-15T09:37:07.292249Z"
    }
   },
   "cell_type": "code",
   "source": "plt.scatter(t_u, t_c)",
   "id": "2b2c3390eb78d9d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f9b498531d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:45:13.551598Z",
     "start_time": "2025-07-15T09:45:13.548936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def model(input_t, weights, bias):\n",
    "    return weights * input_t + bias\n",
    "\n",
    "def loss_fn(output_t, input_t):\n",
    "    squared_diffs = (output_t - input_t) ** 2\n",
    "    return squared_diffs.mean()"
   ],
   "id": "aef31eada6efb5b7",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:46:11.386545Z",
     "start_time": "2025-07-15T09:46:11.382544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w = torch.ones(())\n",
    "b = torch.zeros(())\n",
    "t_new = model(t_u, w, b)\n",
    "t_new"
   ],
   "id": "21fe3b930b62d937",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000,\n",
       "        21.8000, 48.4000, 60.4000, 68.4000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:46:18.181946Z",
     "start_time": "2025-07-15T09:46:18.177616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = loss_fn(t_new, t_c)\n",
    "loss"
   ],
   "id": "123b87f82977dbfd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1763.8848)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:56:56.886123Z",
     "start_time": "2025-07-15T09:56:56.881365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "delta = 0.1\n",
    "loss_rate_of_change_w = (loss_fn(model(t_u, w + delta, b), t_c) -\n",
    "                         loss_fn(model(t_u, w - delta, b), t_c) /\n",
    "                         (2.0 * delta))\n",
    "loss_rate_of_change_w"
   ],
   "id": "f9cdf47f2721e19e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4462.7925)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:58:39.894258Z",
     "start_time": "2025-07-15T09:58:39.891591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "learning_rate = 1e-2\n",
    "w = w - learning_rate * loss_rate_of_change_w"
   ],
   "id": "130b7d9221ac068f",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T09:59:28.197322Z",
     "start_time": "2025-07-15T09:59:28.193533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_rate_of_change_b = (loss_fn(model(t_u, w, b + delta), t_c) -\n",
    "                         loss_fn(model(t_u, w, b - delta), t_c) /\n",
    "                         (2.0 * delta))\n",
    "b = b - learning_rate * loss_rate_of_change_b"
   ],
   "id": "e8e2b3c233683be2",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T10:13:03.471343Z",
     "start_time": "2025-07-15T10:13:03.468559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dloss_fn(out_t, act_t):\n",
    "    return 2 * (out_t - act_t) / out_t.size(0)\n",
    "\n",
    "def dmodel_dw(in_t):\n",
    "    return in_t\n",
    "\n",
    "def dmodel_db():\n",
    "    return 1.0"
   ],
   "id": "b797398fcb0ff3ba",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T10:06:54.213477Z",
     "start_time": "2025-07-15T10:06:54.208209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def grad_fn(in_t, act_t, out_t):\n",
    "    dloss_dtp = dloss_fn(out_t, act_t)\n",
    "    dloss_dw = dloss_dtp * dmodel_dw(in_t)\n",
    "    dloss_db = dloss_dtp * dmodel_db()\n",
    "    return torch.stack([dloss_dw.sum(), dloss_db.sum()])"
   ],
   "id": "d8055093a18ec3e8",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T10:22:01.210452Z",
     "start_time": "2025-07-15T10:22:01.207048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def training_loop(n_epochs, lr, params, in_t, act_t):\n",
    "    final_loss = 0.0\n",
    "    for epoch in range(n_epochs):\n",
    "        weights, bias = params\n",
    "\n",
    "        out_t = model(in_t, weights, bias)\n",
    "        loss_val = loss_fn(out_t, act_t)\n",
    "        grad = grad_fn(in_t, act_t, out_t)\n",
    "\n",
    "        params = params - lr * grad\n",
    "\n",
    "        if (epoch + 1) % 200 == 0:\n",
    "            print(f'    Epoch {epoch + 1}, Loss {float(loss_val)}')\n",
    "        final_loss = loss_val\n",
    "\n",
    "    print(f'Params: {params}')\n",
    "    print(f'Final Loss: {final_loss}')\n",
    "    return params"
   ],
   "id": "a78fca1f030d7b29",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T10:16:37.063218Z",
     "start_time": "2025-07-15T10:16:37.039048Z"
    }
   },
   "cell_type": "code",
   "source": "training_loop(100, 1e-2, params=torch.tensor([1.0, 0.0]), in_t=t_u, act_t=t_c)",
   "id": "1b4d0e8d86423825",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 1, Loss 1763.884765625\n",
      "    Epoch 2, Loss 5802484.5\n",
      "    Epoch 3, Loss 19408029696.0\n",
      "    Epoch 4, Loss 64915905708032.0\n",
      "    Epoch 5, Loss 2.1713052546105344e+17\n",
      "    Epoch 6, Loss 7.262575831529281e+20\n",
      "    Epoch 7, Loss 2.429183416467663e+24\n",
      "    Epoch 8, Loss 8.125122549611731e+27\n",
      "    Epoch 9, Loss 2.717688212084259e+31\n",
      "    Epoch 10, Loss 9.090110518901907e+34\n",
      "    Epoch 11, Loss inf\n",
      "    Epoch 12, Loss inf\n",
      "    Epoch 13, Loss inf\n",
      "    Epoch 14, Loss inf\n",
      "    Epoch 15, Loss inf\n",
      "    Epoch 16, Loss inf\n",
      "    Epoch 17, Loss inf\n",
      "    Epoch 18, Loss inf\n",
      "    Epoch 19, Loss inf\n",
      "    Epoch 20, Loss inf\n",
      "    Epoch 21, Loss inf\n",
      "    Epoch 22, Loss inf\n",
      "    Epoch 23, Loss nan\n",
      "    Epoch 24, Loss nan\n",
      "    Epoch 25, Loss nan\n",
      "    Epoch 26, Loss nan\n",
      "    Epoch 27, Loss nan\n",
      "    Epoch 28, Loss nan\n",
      "    Epoch 29, Loss nan\n",
      "    Epoch 30, Loss nan\n",
      "    Epoch 31, Loss nan\n",
      "    Epoch 32, Loss nan\n",
      "    Epoch 33, Loss nan\n",
      "    Epoch 34, Loss nan\n",
      "    Epoch 35, Loss nan\n",
      "    Epoch 36, Loss nan\n",
      "    Epoch 37, Loss nan\n",
      "    Epoch 38, Loss nan\n",
      "    Epoch 39, Loss nan\n",
      "    Epoch 40, Loss nan\n",
      "    Epoch 41, Loss nan\n",
      "    Epoch 42, Loss nan\n",
      "    Epoch 43, Loss nan\n",
      "    Epoch 44, Loss nan\n",
      "    Epoch 45, Loss nan\n",
      "    Epoch 46, Loss nan\n",
      "    Epoch 47, Loss nan\n",
      "    Epoch 48, Loss nan\n",
      "    Epoch 49, Loss nan\n",
      "    Epoch 50, Loss nan\n",
      "    Epoch 51, Loss nan\n",
      "    Epoch 52, Loss nan\n",
      "    Epoch 53, Loss nan\n",
      "    Epoch 54, Loss nan\n",
      "    Epoch 55, Loss nan\n",
      "    Epoch 56, Loss nan\n",
      "    Epoch 57, Loss nan\n",
      "    Epoch 58, Loss nan\n",
      "    Epoch 59, Loss nan\n",
      "    Epoch 60, Loss nan\n",
      "    Epoch 61, Loss nan\n",
      "    Epoch 62, Loss nan\n",
      "    Epoch 63, Loss nan\n",
      "    Epoch 64, Loss nan\n",
      "    Epoch 65, Loss nan\n",
      "    Epoch 66, Loss nan\n",
      "    Epoch 67, Loss nan\n",
      "    Epoch 68, Loss nan\n",
      "    Epoch 69, Loss nan\n",
      "    Epoch 70, Loss nan\n",
      "    Epoch 71, Loss nan\n",
      "    Epoch 72, Loss nan\n",
      "    Epoch 73, Loss nan\n",
      "    Epoch 74, Loss nan\n",
      "    Epoch 75, Loss nan\n",
      "    Epoch 76, Loss nan\n",
      "    Epoch 77, Loss nan\n",
      "    Epoch 78, Loss nan\n",
      "    Epoch 79, Loss nan\n",
      "    Epoch 80, Loss nan\n",
      "    Epoch 81, Loss nan\n",
      "    Epoch 82, Loss nan\n",
      "    Epoch 83, Loss nan\n",
      "    Epoch 84, Loss nan\n",
      "    Epoch 85, Loss nan\n",
      "    Epoch 86, Loss nan\n",
      "    Epoch 87, Loss nan\n",
      "    Epoch 88, Loss nan\n",
      "    Epoch 89, Loss nan\n",
      "    Epoch 90, Loss nan\n",
      "    Epoch 91, Loss nan\n",
      "    Epoch 92, Loss nan\n",
      "    Epoch 93, Loss nan\n",
      "    Epoch 94, Loss nan\n",
      "    Epoch 95, Loss nan\n",
      "    Epoch 96, Loss nan\n",
      "    Epoch 97, Loss nan\n",
      "    Epoch 98, Loss nan\n",
      "    Epoch 99, Loss nan\n",
      "    Epoch 100, Loss nan\n",
      "Params: tensor([nan, nan])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T10:16:53.247071Z",
     "start_time": "2025-07-15T10:16:53.222893Z"
    }
   },
   "cell_type": "code",
   "source": "training_loop(100, 1e-3, params=torch.tensor([1.0, 0.0]), in_t=t_u, act_t=t_c)",
   "id": "4611576725aeafb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 1, Loss 1763.884765625\n",
      "    Epoch 2, Loss 41399.59765625\n",
      "    Epoch 3, Loss 986624.625\n",
      "    Epoch 4, Loss 23528170.0\n",
      "    Epoch 5, Loss 561094464.0\n",
      "    Epoch 6, Loss 13380874240.0\n",
      "    Epoch 7, Loss 319104483328.0\n",
      "    Epoch 8, Loss 7609941753856.0\n",
      "    Epoch 9, Loss 181480420540416.0\n",
      "    Epoch 10, Loss 4327910500466688.0\n",
      "    Epoch 11, Loss 1.0321116508926771e+17\n",
      "    Epoch 12, Loss 2.461360407747494e+18\n",
      "    Epoch 13, Loss 5.869806156751936e+19\n",
      "    Epoch 14, Loss 1.3998199544408776e+21\n",
      "    Epoch 15, Loss 3.338263274850858e+22\n",
      "    Epoch 16, Loss 7.961026752245693e+23\n",
      "    Epoch 17, Loss 1.8985296766941502e+25\n",
      "    Epoch 18, Loss 4.527576982018665e+26\n",
      "    Epoch 19, Loss 1.0797280117197434e+28\n",
      "    Epoch 20, Loss 2.5749145261349537e+29\n",
      "    Epoch 21, Loss 6.140605718892351e+30\n",
      "    Epoch 22, Loss 1.4644000858063465e+32\n",
      "    Epoch 23, Loss 3.492271559755413e+33\n",
      "    Epoch 24, Loss 8.328302025766313e+34\n",
      "    Epoch 25, Loss 1.986117406288558e+36\n",
      "    Epoch 26, Loss inf\n",
      "    Epoch 27, Loss inf\n",
      "    Epoch 28, Loss inf\n",
      "    Epoch 29, Loss inf\n",
      "    Epoch 30, Loss inf\n",
      "    Epoch 31, Loss inf\n",
      "    Epoch 32, Loss inf\n",
      "    Epoch 33, Loss inf\n",
      "    Epoch 34, Loss inf\n",
      "    Epoch 35, Loss inf\n",
      "    Epoch 36, Loss inf\n",
      "    Epoch 37, Loss inf\n",
      "    Epoch 38, Loss inf\n",
      "    Epoch 39, Loss inf\n",
      "    Epoch 40, Loss inf\n",
      "    Epoch 41, Loss inf\n",
      "    Epoch 42, Loss inf\n",
      "    Epoch 43, Loss inf\n",
      "    Epoch 44, Loss inf\n",
      "    Epoch 45, Loss inf\n",
      "    Epoch 46, Loss inf\n",
      "    Epoch 47, Loss inf\n",
      "    Epoch 48, Loss inf\n",
      "    Epoch 49, Loss inf\n",
      "    Epoch 50, Loss inf\n",
      "    Epoch 51, Loss inf\n",
      "    Epoch 52, Loss inf\n",
      "    Epoch 53, Loss inf\n",
      "    Epoch 54, Loss nan\n",
      "    Epoch 55, Loss nan\n",
      "    Epoch 56, Loss nan\n",
      "    Epoch 57, Loss nan\n",
      "    Epoch 58, Loss nan\n",
      "    Epoch 59, Loss nan\n",
      "    Epoch 60, Loss nan\n",
      "    Epoch 61, Loss nan\n",
      "    Epoch 62, Loss nan\n",
      "    Epoch 63, Loss nan\n",
      "    Epoch 64, Loss nan\n",
      "    Epoch 65, Loss nan\n",
      "    Epoch 66, Loss nan\n",
      "    Epoch 67, Loss nan\n",
      "    Epoch 68, Loss nan\n",
      "    Epoch 69, Loss nan\n",
      "    Epoch 70, Loss nan\n",
      "    Epoch 71, Loss nan\n",
      "    Epoch 72, Loss nan\n",
      "    Epoch 73, Loss nan\n",
      "    Epoch 74, Loss nan\n",
      "    Epoch 75, Loss nan\n",
      "    Epoch 76, Loss nan\n",
      "    Epoch 77, Loss nan\n",
      "    Epoch 78, Loss nan\n",
      "    Epoch 79, Loss nan\n",
      "    Epoch 80, Loss nan\n",
      "    Epoch 81, Loss nan\n",
      "    Epoch 82, Loss nan\n",
      "    Epoch 83, Loss nan\n",
      "    Epoch 84, Loss nan\n",
      "    Epoch 85, Loss nan\n",
      "    Epoch 86, Loss nan\n",
      "    Epoch 87, Loss nan\n",
      "    Epoch 88, Loss nan\n",
      "    Epoch 89, Loss nan\n",
      "    Epoch 90, Loss nan\n",
      "    Epoch 91, Loss nan\n",
      "    Epoch 92, Loss nan\n",
      "    Epoch 93, Loss nan\n",
      "    Epoch 94, Loss nan\n",
      "    Epoch 95, Loss nan\n",
      "    Epoch 96, Loss nan\n",
      "    Epoch 97, Loss nan\n",
      "    Epoch 98, Loss nan\n",
      "    Epoch 99, Loss nan\n",
      "    Epoch 100, Loss nan\n",
      "Params: tensor([nan, nan])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T10:16:58.831810Z",
     "start_time": "2025-07-15T10:16:58.808360Z"
    }
   },
   "cell_type": "code",
   "source": "training_loop(100, 1e-4, params=torch.tensor([1.0, 0.0]), in_t=t_u, act_t=t_c)",
   "id": "afd173a20898dac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 1, Loss 1763.884765625\n",
      "    Epoch 2, Loss 323.09051513671875\n",
      "    Epoch 3, Loss 78.92963409423828\n",
      "    Epoch 4, Loss 37.5528450012207\n",
      "    Epoch 5, Loss 30.540283203125\n",
      "    Epoch 6, Loss 29.351154327392578\n",
      "    Epoch 7, Loss 29.148883819580078\n",
      "    Epoch 8, Loss 29.113847732543945\n",
      "    Epoch 9, Loss 29.107145309448242\n",
      "    Epoch 10, Loss 29.105247497558594\n",
      "    Epoch 11, Loss 29.104167938232422\n",
      "    Epoch 12, Loss 29.103221893310547\n",
      "    Epoch 13, Loss 29.102294921875\n",
      "    Epoch 14, Loss 29.10137939453125\n",
      "    Epoch 15, Loss 29.100465774536133\n",
      "    Epoch 16, Loss 29.09954833984375\n",
      "    Epoch 17, Loss 29.098630905151367\n",
      "    Epoch 18, Loss 29.09771728515625\n",
      "    Epoch 19, Loss 29.0967960357666\n",
      "    Epoch 20, Loss 29.09588050842285\n",
      "    Epoch 21, Loss 29.094959259033203\n",
      "    Epoch 22, Loss 29.09404945373535\n",
      "    Epoch 23, Loss 29.0931339263916\n",
      "    Epoch 24, Loss 29.09221649169922\n",
      "    Epoch 25, Loss 29.09130096435547\n",
      "    Epoch 26, Loss 29.09038543701172\n",
      "    Epoch 27, Loss 29.08946418762207\n",
      "    Epoch 28, Loss 29.088550567626953\n",
      "    Epoch 29, Loss 29.087635040283203\n",
      "    Epoch 30, Loss 29.086713790893555\n",
      "    Epoch 31, Loss 29.085803985595703\n",
      "    Epoch 32, Loss 29.084888458251953\n",
      "    Epoch 33, Loss 29.083967208862305\n",
      "    Epoch 34, Loss 29.083057403564453\n",
      "    Epoch 35, Loss 29.082141876220703\n",
      "    Epoch 36, Loss 29.081220626831055\n",
      "    Epoch 37, Loss 29.08030891418457\n",
      "    Epoch 38, Loss 29.079389572143555\n",
      "    Epoch 39, Loss 29.078474044799805\n",
      "    Epoch 40, Loss 29.07756233215332\n",
      "    Epoch 41, Loss 29.076648712158203\n",
      "    Epoch 42, Loss 29.07573127746582\n",
      "    Epoch 43, Loss 29.074811935424805\n",
      "    Epoch 44, Loss 29.073894500732422\n",
      "    Epoch 45, Loss 29.072980880737305\n",
      "    Epoch 46, Loss 29.07206916809082\n",
      "    Epoch 47, Loss 29.071147918701172\n",
      "    Epoch 48, Loss 29.070234298706055\n",
      "    Epoch 49, Loss 29.06932258605957\n",
      "    Epoch 50, Loss 29.068401336669922\n",
      "    Epoch 51, Loss 29.067485809326172\n",
      "    Epoch 52, Loss 29.066566467285156\n",
      "    Epoch 53, Loss 29.065656661987305\n",
      "    Epoch 54, Loss 29.064741134643555\n",
      "    Epoch 55, Loss 29.063825607299805\n",
      "    Epoch 56, Loss 29.062910079956055\n",
      "    Epoch 57, Loss 29.061994552612305\n",
      "    Epoch 58, Loss 29.061079025268555\n",
      "    Epoch 59, Loss 29.060169219970703\n",
      "    Epoch 60, Loss 29.059247970581055\n",
      "    Epoch 61, Loss 29.05833625793457\n",
      "    Epoch 62, Loss 29.057415008544922\n",
      "    Epoch 63, Loss 29.056507110595703\n",
      "    Epoch 64, Loss 29.055585861206055\n",
      "    Epoch 65, Loss 29.05467414855957\n",
      "    Epoch 66, Loss 29.053760528564453\n",
      "    Epoch 67, Loss 29.05284309387207\n",
      "    Epoch 68, Loss 29.051929473876953\n",
      "    Epoch 69, Loss 29.05101203918457\n",
      "    Epoch 70, Loss 29.050098419189453\n",
      "    Epoch 71, Loss 29.049182891845703\n",
      "    Epoch 72, Loss 29.04827308654785\n",
      "    Epoch 73, Loss 29.04734992980957\n",
      "    Epoch 74, Loss 29.04644203186035\n",
      "    Epoch 75, Loss 29.045530319213867\n",
      "    Epoch 76, Loss 29.04461097717285\n",
      "    Epoch 77, Loss 29.043699264526367\n",
      "    Epoch 78, Loss 29.042783737182617\n",
      "    Epoch 79, Loss 29.0418701171875\n",
      "    Epoch 80, Loss 29.04095458984375\n",
      "    Epoch 81, Loss 29.0400390625\n",
      "    Epoch 82, Loss 29.039121627807617\n",
      "    Epoch 83, Loss 29.038209915161133\n",
      "    Epoch 84, Loss 29.037294387817383\n",
      "    Epoch 85, Loss 29.036378860473633\n",
      "    Epoch 86, Loss 29.035463333129883\n",
      "    Epoch 87, Loss 29.03455352783203\n",
      "    Epoch 88, Loss 29.03363609313965\n",
      "    Epoch 89, Loss 29.03272247314453\n",
      "    Epoch 90, Loss 29.031810760498047\n",
      "    Epoch 91, Loss 29.030895233154297\n",
      "    Epoch 92, Loss 29.02997589111328\n",
      "    Epoch 93, Loss 29.02906608581543\n",
      "    Epoch 94, Loss 29.02815055847168\n",
      "    Epoch 95, Loss 29.02723503112793\n",
      "    Epoch 96, Loss 29.026323318481445\n",
      "    Epoch 97, Loss 29.025409698486328\n",
      "    Epoch 98, Loss 29.024492263793945\n",
      "    Epoch 99, Loss 29.023582458496094\n",
      "    Epoch 100, Loss 29.022666931152344\n",
      "Params: tensor([ 0.2327, -0.0438])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2327, -0.0438])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T10:18:49.822322Z",
     "start_time": "2025-07-15T10:18:49.818748Z"
    }
   },
   "cell_type": "code",
   "source": "t_un = 0.1 * t_u",
   "id": "50d10d6abab1bdb1",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T10:23:58.869586Z",
     "start_time": "2025-07-15T10:23:58.489172Z"
    }
   },
   "cell_type": "code",
   "source": "fin_params = training_loop(5000, 1e-2, params=torch.tensor([1.0, 0.0]), in_t=t_un, act_t=t_c)",
   "id": "7a7f7fe91d15465",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Epoch 200, Loss 16.60806655883789\n",
      "    Epoch 400, Loss 9.857804298400879\n",
      "    Epoch 600, Loss 6.438284397125244\n",
      "    Epoch 800, Loss 4.706046104431152\n",
      "    Epoch 1000, Loss 3.828537940979004\n",
      "    Epoch 1200, Loss 3.3840177059173584\n",
      "    Epoch 1400, Loss 3.158830404281616\n",
      "    Epoch 1600, Loss 3.0447587966918945\n",
      "    Epoch 1800, Loss 2.986973524093628\n",
      "    Epoch 2000, Loss 2.957697868347168\n",
      "    Epoch 2200, Loss 2.9428696632385254\n",
      "    Epoch 2400, Loss 2.935356378555298\n",
      "    Epoch 2600, Loss 2.931553840637207\n",
      "    Epoch 2800, Loss 2.929626226425171\n",
      "    Epoch 3000, Loss 2.9286484718322754\n",
      "    Epoch 3200, Loss 2.9281539916992188\n",
      "    Epoch 3400, Loss 2.927903890609741\n",
      "    Epoch 3600, Loss 2.9277760982513428\n",
      "    Epoch 3800, Loss 2.927712917327881\n",
      "    Epoch 4000, Loss 2.927680253982544\n",
      "    Epoch 4200, Loss 2.927663564682007\n",
      "    Epoch 4400, Loss 2.9276540279388428\n",
      "    Epoch 4600, Loss 2.9276504516601562\n",
      "    Epoch 4800, Loss 2.9276480674743652\n",
      "    Epoch 5000, Loss 2.927647590637207\n",
      "Params: tensor([  5.3671, -17.3012])\n",
      "Final Loss: 2.927647590637207\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T10:26:08.430785Z",
     "start_time": "2025-07-15T10:26:08.321337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_t = model(t_un, *fin_params)\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.xlabel('Temperature (F)')\n",
    "plt.ylabel('Temperature (C)')\n",
    "plt.plot(t_u.numpy(), final_t.detach().numpy())\n",
    "plt.plot(t_u.numpy(), t_c.numpy(), 'o')"
   ],
   "id": "837b07f73a20807a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9b4a1437a0>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Autograd",
   "id": "c968c9fe58e2fd15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:40:08.934486Z",
     "start_time": "2025-07-15T11:40:06.975747Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "79f6ca48da23aa11",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:57:45.465434Z",
     "start_time": "2025-07-15T11:57:45.460970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Same as before\n",
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]    # In Celsius\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]    # No units\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)\n",
    "\n",
    "def model(x, weights, bias):\n",
    "    return weights * x + bias\n",
    "\n",
    "def loss_fn(y_pred, y_true):\n",
    "    squared_diffs = (y_pred - y_true) ** 2\n",
    "    return squared_diffs.mean()"
   ],
   "id": "315599ab90841dfc",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:45:36.640098Z",
     "start_time": "2025-07-15T11:45:36.637016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# requires_grad=True automatically keeps track of tensors resulting from operations on params\n",
    "parameters = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "parameters.grad is None"
   ],
   "id": "25fbeb21a246aa15",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:45:37.330691Z",
     "start_time": "2025-07-15T11:45:37.324178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss = loss_fn(model(t_u, *parameters), t_c)\n",
    "loss.backward()"
   ],
   "id": "4f03ed60fc52cf10",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:45:38.100202Z",
     "start_time": "2025-07-15T11:45:38.092362Z"
    }
   },
   "cell_type": "code",
   "source": "parameters.grad",
   "id": "45fb8c0820ec5560",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4517.2969,   82.6000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:48:03.162658Z",
     "start_time": "2025-07-15T11:48:03.156436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Gradients accumulate over time, so we have to zero them\n",
    "if parameters.grad is not None:\n",
    "    parameters.grad.zero_()"
   ],
   "id": "a3292c2b3de7674f",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:57:49.398995Z",
     "start_time": "2025-07-15T11:57:49.394834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# New training loop with autograd\n",
    "def training_loop(n_epochs, lr, params, t_in, t_act):\n",
    "    for epoch in range(n_epochs):\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "\n",
    "        out = model(t_in, *params)\n",
    "        loss_val = loss_fn(out, t_act)\n",
    "        loss_val.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            params -= lr * params.grad\n",
    "\n",
    "        if (epoch + 1) % 200 == 0:\n",
    "            print(f'Epoch: {epoch + 1}, Loss: {float(loss_val)}')\n",
    "\n",
    "    return params"
   ],
   "id": "c3d7374d14a99858",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:58:40.015651Z",
     "start_time": "2025-07-15T11:58:38.991080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t_un = 0.1 * t_u\n",
    "parameters = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "updated_params = training_loop(5000, 1e-2, parameters, t_un, t_c)"
   ],
   "id": "5bed3269dcb503b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200, Loss: 16.60806655883789\n",
      "Epoch: 400, Loss: 9.857802391052246\n",
      "Epoch: 600, Loss: 6.438284397125244\n",
      "Epoch: 800, Loss: 4.706046104431152\n",
      "Epoch: 1000, Loss: 3.828537940979004\n",
      "Epoch: 1200, Loss: 3.3840177059173584\n",
      "Epoch: 1400, Loss: 3.158830404281616\n",
      "Epoch: 1600, Loss: 3.0447587966918945\n",
      "Epoch: 1800, Loss: 2.986973524093628\n",
      "Epoch: 2000, Loss: 2.957697868347168\n",
      "Epoch: 2200, Loss: 2.9428696632385254\n",
      "Epoch: 2400, Loss: 2.935356378555298\n",
      "Epoch: 2600, Loss: 2.931553840637207\n",
      "Epoch: 2800, Loss: 2.929626226425171\n",
      "Epoch: 3000, Loss: 2.9286484718322754\n",
      "Epoch: 3200, Loss: 2.9281539916992188\n",
      "Epoch: 3400, Loss: 2.927903890609741\n",
      "Epoch: 3600, Loss: 2.9277760982513428\n",
      "Epoch: 3800, Loss: 2.927712917327881\n",
      "Epoch: 4000, Loss: 2.9276793003082275\n",
      "Epoch: 4200, Loss: 2.9276628494262695\n",
      "Epoch: 4400, Loss: 2.9276556968688965\n",
      "Epoch: 4600, Loss: 2.9276490211486816\n",
      "Epoch: 4800, Loss: 2.927647590637207\n",
      "Epoch: 5000, Loss: 2.9276468753814697\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Optimizers",
   "id": "d903ceda0113b97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T12:00:17.633121Z",
     "start_time": "2025-07-15T12:00:17.629064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "dir(optim)"
   ],
   "id": "7d64a7987e50b66",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASGD',\n",
       " 'Adadelta',\n",
       " 'Adafactor',\n",
       " 'Adagrad',\n",
       " 'Adam',\n",
       " 'AdamW',\n",
       " 'Adamax',\n",
       " 'LBFGS',\n",
       " 'NAdam',\n",
       " 'Optimizer',\n",
       " 'RAdam',\n",
       " 'RMSprop',\n",
       " 'Rprop',\n",
       " 'SGD',\n",
       " 'SparseAdam',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_adafactor',\n",
       " '_functional',\n",
       " 'lr_scheduler',\n",
       " 'swa_utils']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T12:03:24.245959Z",
     "start_time": "2025-07-15T12:03:23.088015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parameters = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-5\n",
    "optimizer = optim.SGD([parameters], lr=learning_rate)"
   ],
   "id": "dba0ffec0a6d8af",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T12:05:21.284238Z",
     "start_time": "2025-07-15T12:05:21.275008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_out = model(t_u, *parameters)\n",
    "loss = loss_fn(model_out, t_c)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "parameters"
   ],
   "id": "4ba0361f2a0a83c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8298, -0.0031], requires_grad=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T12:07:52.351662Z",
     "start_time": "2025-07-15T12:07:52.348715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# New training loop with optimizer\n",
    "def training_loop(n_epochs, optim_, params, t_in, t_act):\n",
    "    for epoch in range(n_epochs):\n",
    "        out = model(t_in, *params)\n",
    "        loss_val = loss_fn(out, t_act)\n",
    "\n",
    "        optim_.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optim_.step()\n",
    "\n",
    "        if (epoch + 1) % 200 == 0:\n",
    "            print(f'Epoch: {epoch + 1}, Loss: {float(loss_val)}')\n",
    "\n",
    "    return params"
   ],
   "id": "527d0b34e9c8ba63",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T12:08:09.559305Z",
     "start_time": "2025-07-15T12:08:08.319093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "t_un = 0.1 * t_u\n",
    "parameters = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([parameters], lr=learning_rate)\n",
    "\n",
    "training_loop(5000, optimizer, parameters, t_un, t_c)"
   ],
   "id": "77296d7c90168233",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200, Loss: 16.608068466186523\n",
      "Epoch: 400, Loss: 9.857809066772461\n",
      "Epoch: 600, Loss: 6.438288688659668\n",
      "Epoch: 800, Loss: 4.706045150756836\n",
      "Epoch: 1000, Loss: 3.828537940979004\n",
      "Epoch: 1200, Loss: 3.3840177059173584\n",
      "Epoch: 1400, Loss: 3.158830404281616\n",
      "Epoch: 1600, Loss: 3.0447587966918945\n",
      "Epoch: 1800, Loss: 2.986973524093628\n",
      "Epoch: 2000, Loss: 2.957697868347168\n",
      "Epoch: 2200, Loss: 2.9428696632385254\n",
      "Epoch: 2400, Loss: 2.935356378555298\n",
      "Epoch: 2600, Loss: 2.931553840637207\n",
      "Epoch: 2800, Loss: 2.929626226425171\n",
      "Epoch: 3000, Loss: 2.9286484718322754\n",
      "Epoch: 3200, Loss: 2.9281539916992188\n",
      "Epoch: 3400, Loss: 2.927903890609741\n",
      "Epoch: 3600, Loss: 2.9277760982513428\n",
      "Epoch: 3800, Loss: 2.927712917327881\n",
      "Epoch: 4000, Loss: 2.9276793003082275\n",
      "Epoch: 4200, Loss: 2.9276628494262695\n",
      "Epoch: 4400, Loss: 2.9276556968688965\n",
      "Epoch: 4600, Loss: 2.9276490211486816\n",
      "Epoch: 4800, Loss: 2.927647590637207\n",
      "Epoch: 5000, Loss: 2.9276468753814697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.3671, -17.3012], requires_grad=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T12:09:28.802704Z",
     "start_time": "2025-07-15T12:09:27.073393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# New optimizer: Adam\n",
    "parameters = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([parameters], lr=learning_rate)\n",
    "\n",
    "training_loop(5000, optimizer, parameters, t_u, t_c)"
   ],
   "id": "38dc306674360edb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200, Loss: 19.082256317138672\n",
      "Epoch: 400, Loss: 10.508146286010742\n",
      "Epoch: 600, Loss: 5.6413798332214355\n",
      "Epoch: 800, Loss: 3.6775739192962646\n",
      "Epoch: 1000, Loss: 3.086698293685913\n",
      "Epoch: 1200, Loss: 2.9531850814819336\n",
      "Epoch: 1400, Loss: 2.9306914806365967\n",
      "Epoch: 1600, Loss: 2.927908182144165\n",
      "Epoch: 1800, Loss: 2.9276609420776367\n",
      "Epoch: 2000, Loss: 2.9276463985443115\n",
      "Epoch: 2200, Loss: 2.9276444911956787\n",
      "Epoch: 2400, Loss: 2.927645206451416\n",
      "Epoch: 2600, Loss: 2.9276463985443115\n",
      "Epoch: 2800, Loss: 2.927644968032837\n",
      "Epoch: 3000, Loss: 2.9276459217071533\n",
      "Epoch: 3200, Loss: 2.9276444911956787\n",
      "Epoch: 3400, Loss: 2.927647352218628\n",
      "Epoch: 3600, Loss: 2.927644968032837\n",
      "Epoch: 3800, Loss: 2.927644968032837\n",
      "Epoch: 4000, Loss: 2.927645683288574\n",
      "Epoch: 4200, Loss: 2.927645206451416\n",
      "Epoch: 4400, Loss: 2.927645683288574\n",
      "Epoch: 4600, Loss: 2.9276463985443115\n",
      "Epoch: 4800, Loss: 2.927645206451416\n",
      "Epoch: 5000, Loss: 2.927645206451416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  0.5368, -17.3048], requires_grad=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train/Validation Split",
   "id": "489083843da4aaa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T13:20:09.762270Z",
     "start_time": "2025-07-15T13:20:09.759042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[n_val:]"
   ],
   "id": "3ce0c92116d3f9f6",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T13:25:37.900516Z",
     "start_time": "2025-07-15T13:25:37.896998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_t_u = t_u[train_indices]\n",
    "val_t_u = t_u[val_indices]\n",
    "\n",
    "train_t_c = t_c[train_indices]\n",
    "val_t_c = t_c[val_indices]\n",
    "\n",
    "train_t_un = train_t_u * 0.1\n",
    "val_t_un = val_t_u * 0.1"
   ],
   "id": "bfe1a705564a166c",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T13:24:16.781169Z",
     "start_time": "2025-07-15T13:24:16.775299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def training_loop(n_epochs, optim_, params, train_tun, train_tc, val_tun, val_tc):\n",
    "    for epoch in range(n_epochs):\n",
    "        train_out = model(train_tun, *params)\n",
    "        train_loss = loss_fn(train_out, train_tc)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_out = model(val_tun, *params)\n",
    "            val_loss = loss_fn(val_out, val_tc)\n",
    "            assert val_loss.requires_grad == False\n",
    "\n",
    "        optim_.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optim_.step()\n",
    "\n",
    "        if epoch <= 3 or (epoch + 1) % 200 == 0:\n",
    "            print(f'Epoch: {epoch + 1}, Train Loss: {float(train_loss)}, Val Loss: {val_loss.float()}')\n",
    "\n",
    "    return params"
   ],
   "id": "f28f7636c90f85eb",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T13:25:54.997565Z",
     "start_time": "2025-07-15T13:25:53.404259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parameters = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([parameters], learning_rate)\n",
    "\n",
    "training_loop(5000, optimizer, parameters, train_t_un, train_t_c, val_t_un, val_t_c)"
   ],
   "id": "18700e32a1003755",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 54.602176666259766, Val Loss: 91.76600646972656\n",
      "Epoch: 2, Train Loss: 28.94879913330078, Val Loss: 53.02854919433594\n",
      "Epoch: 3, Train Loss: 24.009109497070312, Val Loss: 42.797889709472656\n",
      "Epoch: 4, Train Loss: 23.025007247924805, Val Loss: 39.56832504272461\n",
      "Epoch: 200, Train Loss: 15.000133514404297, Val Loss: 24.509685516357422\n",
      "Epoch: 400, Train Loss: 10.155324935913086, Val Loss: 16.305133819580078\n",
      "Epoch: 600, Train Loss: 7.2239508628845215, Val Loss: 11.313128471374512\n",
      "Epoch: 800, Train Loss: 5.450300216674805, Val Loss: 8.271053314208984\n",
      "Epoch: 1000, Train Loss: 4.377147674560547, Val Loss: 6.41361141204834\n",
      "Epoch: 1200, Train Loss: 3.7278332710266113, Val Loss: 5.276676177978516\n",
      "Epoch: 1400, Train Loss: 3.33495831489563, Val Loss: 4.578587055206299\n",
      "Epoch: 1600, Train Loss: 3.0972490310668945, Val Loss: 4.148285865783691\n",
      "Epoch: 1800, Train Loss: 2.9534213542938232, Val Loss: 3.8817737102508545\n",
      "Epoch: 2000, Train Loss: 2.866398811340332, Val Loss: 3.715726613998413\n",
      "Epoch: 2200, Train Loss: 2.813746452331543, Val Loss: 3.611538887023926\n",
      "Epoch: 2400, Train Loss: 2.781886577606201, Val Loss: 3.545597553253174\n",
      "Epoch: 2600, Train Loss: 2.7626092433929443, Val Loss: 3.5034446716308594\n",
      "Epoch: 2800, Train Loss: 2.750946521759033, Val Loss: 3.476187229156494\n",
      "Epoch: 3000, Train Loss: 2.743889331817627, Val Loss: 3.4583301544189453\n",
      "Epoch: 3200, Train Loss: 2.739619493484497, Val Loss: 3.446465492248535\n",
      "Epoch: 3400, Train Loss: 2.7370359897613525, Val Loss: 3.438462734222412\n",
      "Epoch: 3600, Train Loss: 2.735473871231079, Val Loss: 3.432978391647339\n",
      "Epoch: 3800, Train Loss: 2.7345263957977295, Val Loss: 3.4291574954986572\n",
      "Epoch: 4000, Train Loss: 2.7339537143707275, Val Loss: 3.4264612197875977\n",
      "Epoch: 4200, Train Loss: 2.733609914779663, Val Loss: 3.424525260925293\n",
      "Epoch: 4400, Train Loss: 2.733400344848633, Val Loss: 3.4231173992156982\n",
      "Epoch: 4600, Train Loss: 2.733273506164551, Val Loss: 3.422084331512451\n",
      "Epoch: 4800, Train Loss: 2.733196258544922, Val Loss: 3.4213180541992188\n",
      "Epoch: 5000, Train Loss: 2.733149528503418, Val Loss: 3.420746088027954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.3152, -17.4214], requires_grad=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calc_forward(t_in, t_act, params, is_train):\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        t_out = model(t_in, *params)\n",
    "        loss_ = loss_fn(t_out, t_act)\n",
    "    return loss_"
   ],
   "id": "16920a30e2084024"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1"
   ],
   "id": "9400d9872ae321ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T13:41:04.575514Z",
     "start_time": "2025-07-15T13:41:04.571331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def model_new(t_in, weights1, weights2, bias):\n",
    "    return weights2 * t_in ** 2 + weights1 * t_in + bias"
   ],
   "id": "6386535322b2f177",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T13:42:40.296918Z",
     "start_time": "2025-07-15T13:42:40.293394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def forward(inputs, targets, params, is_train):\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        outs = model_new(inputs, *params)\n",
    "        loss_ = loss_fn(outs, targets)\n",
    "    return loss_"
   ],
   "id": "ff0d99e5b59df55e",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T13:41:06.326722Z",
     "start_time": "2025-07-15T13:41:06.320151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def training_loop(n_epochs, params, optim_, train_data, train_targets, val_data, val_targets):\n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = forward(train_data, train_targets, params, True)\n",
    "        val_loss = forward(val_data, val_targets, params, False)\n",
    "\n",
    "        optim_.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optim_.step()\n",
    "\n",
    "        if epoch <= 3 or (epoch + 1) % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1}    Train Loss: {train_loss.float()}    Val Loss: {val_loss.float()}')\n",
    "    return params"
   ],
   "id": "881072df5854414f",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T13:42:51.130427Z",
     "start_time": "2025-07-15T13:42:49.471627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parameters = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.SGD([parameters], learning_rate)\n",
    "training_loop(5000, parameters, optimizer, train_t_un, train_t_c, val_t_un, val_t_c)"
   ],
   "id": "43bffb6446060a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1    Train Loss: 562.052001953125    Val Loss: 681.0538330078125\n",
      "Epoch 2    Train Loss: 380.4105224609375    Val Loss: 451.0948791503906\n",
      "Epoch 3    Train Loss: 258.93408203125    Val Loss: 299.12115478515625\n",
      "Epoch 4    Train Loss: 177.6937713623047    Val Loss: 198.969482421875\n",
      "Epoch 200    Train Loss: 12.909128189086914    Val Loss: 15.54959487915039\n",
      "Epoch 400    Train Loss: 12.175434112548828    Val Loss: 14.329854011535645\n",
      "Epoch 600    Train Loss: 11.490619659423828    Val Loss: 13.218446731567383\n",
      "Epoch 800    Train Loss: 10.851422309875488    Val Loss: 12.207230567932129\n",
      "Epoch 1000    Train Loss: 10.254799842834473    Val Loss: 11.288636207580566\n",
      "Epoch 1200    Train Loss: 9.697917938232422    Val Loss: 10.45562744140625\n",
      "Epoch 1400    Train Loss: 9.178129196166992    Val Loss: 9.701674461364746\n",
      "Epoch 1600    Train Loss: 8.692960739135742    Val Loss: 9.020700454711914\n",
      "Epoch 1800    Train Loss: 8.240105628967285    Val Loss: 8.407062530517578\n",
      "Epoch 2000    Train Loss: 7.817412376403809    Val Loss: 7.855532169342041\n",
      "Epoch 2200    Train Loss: 7.42287015914917    Val Loss: 7.361238956451416\n",
      "Epoch 2400    Train Loss: 7.054602146148682    Val Loss: 6.919665813446045\n",
      "Epoch 2600    Train Loss: 6.710860729217529    Val Loss: 6.5266289710998535\n",
      "Epoch 2800    Train Loss: 6.390009880065918    Val Loss: 6.178239345550537\n",
      "Epoch 3000    Train Loss: 6.090518951416016    Val Loss: 5.8708815574646\n",
      "Epoch 3200    Train Loss: 5.810972690582275    Val Loss: 5.601222515106201\n",
      "Epoch 3400    Train Loss: 5.550040245056152    Val Loss: 5.366156101226807\n",
      "Epoch 3600    Train Loss: 5.306478500366211    Val Loss: 5.162807941436768\n",
      "Epoch 3800    Train Loss: 5.0791335105896    Val Loss: 4.988514423370361\n",
      "Epoch 4000    Train Loss: 4.866920471191406    Val Loss: 4.840808868408203\n",
      "Epoch 4200    Train Loss: 4.668834209442139    Val Loss: 4.717404842376709\n",
      "Epoch 4400    Train Loss: 4.4839324951171875    Val Loss: 4.616189956665039\n",
      "Epoch 4600    Train Loss: 4.311337471008301    Val Loss: 4.535202980041504\n",
      "Epoch 4800    Train Loss: 4.150228023529053    Val Loss: 4.472636699676514\n",
      "Epoch 5000    Train Loss: 3.99983811378479    Val Loss: 4.426812648773193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.0164,  0.5915, -0.9676], requires_grad=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "a) Only the parameters had to be updated to include one more entry for the new weight\n",
    "b) The training loop in general stays the same, including the calculation of the loss, updating the parameters...\n",
    "c) The resulting loss is higher than before\n",
    "d) The output is worse in general"
   ],
   "id": "fbb4e37aa1da6c7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "50ba529f5358867e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
