{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Chapter 10\n",
    "\n",
    "### Exercise 1"
   ],
   "id": "829ecfb340ecd766"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T12:56:59.609438Z",
     "start_time": "2025-08-07T12:56:56.883756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import set_mode\n",
    "\n",
    "set_mode('local')\n",
    "\n",
    "import time\n",
    "from dsets import LunaDataset"
   ],
   "id": "9bb241a442994148",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def time_iterations(iter_count):\n",
    "    ds = LunaDataset()\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(iter_count):\n",
    "        _ = ds[i]\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'{iter_count} iterations finished in {end - start} seconds.')\n",
    "\n",
    "def time_last_iterations(iter_count):\n",
    "    ds = LunaDataset()\n",
    "\n",
    "    start = time.time()\n",
    "    for i in range(iter_count):\n",
    "        _ = ds[-i]\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'{iter_count} iterations finished in {end - start} seconds.')"
   ],
   "id": "3854d867ed9d01a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "time_iterations(1000)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "a) First run finished in 141 seconds.",
   "id": "b94b52c6ea58a5db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "time_iterations(1000)",
   "id": "f69407f3d0a1dd6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "b) Second run finished in under 1 second.",
   "id": "d8c235c972b74872"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "time_iterations(1000)",
   "id": "61884f6460927396",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "c) After clearing the cache, the runtime is back to 200 seconds.",
   "id": "4c458482c35c04ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "time_last_iterations(1000)\n",
    "time_last_iterations(1000)"
   ],
   "id": "751cdf8edb0571a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "d) Using the last 1000 samples has no impact on the runtime after being cached.",
   "id": "37a1754b25edbc2d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exercise 2",
   "id": "415576fd7e470b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "time_iterations(1000)\n",
    "time_iterations(1000)"
   ],
   "id": "76c31c348518362e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After randomizing the list, both runs take quite a long time.",
   "id": "5a81b05a881f8bf2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exercise 3",
   "id": "fb3d6087a759f92e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "time_iterations(1000)\n",
    "time_iterations(1000)"
   ],
   "id": "32ab0c8e08294fff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The getCt decorator does have an impact on the first loop. The second one remains the same, however.",
   "id": "c4e1b2fa9eff3240"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Chapter 11\n",
    "\n",
    "### Exercise 1"
   ],
   "id": "cae87fd6c45d669b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T12:56:59.620495Z",
     "start_time": "2025-08-07T12:56:59.617907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import set_mode\n",
    "\n",
    "set_mode('local')\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ],
   "id": "a04fe5c6eabdb9d2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def time_dataloader(num_workers, batch_size=1):\n",
    "    # We only time the validation set, so it's faster\n",
    "    dataset = LunaDataset(\n",
    "        val_stride = 10,\n",
    "        is_val_set = True,\n",
    "    )\n",
    "\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size  = batch_size,\n",
    "        num_workers = num_workers,\n",
    "        pin_memory  = True\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    for _ in tqdm(data_loader):\n",
    "        pass\n",
    "\n",
    "    print(f'Finished in {time.time() - start_time:.2f} seconds. Num_workers: {num_workers}.')"
   ],
   "id": "afb49aa25f491f56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "time_dataloader(4)",
   "id": "ffbc85aaac1e573c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Before cache is filled, iterating over the 55107 samples in the validation set takes 8 minutes and 10 seconds.",
   "id": "f59068a8e4b2a0aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "time_dataloader(4)",
   "id": "3802cafccd7ae24d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The run time significantly reduces after the first epoch, as the data is already placed in the on disk cache now. The time to iterate over the validation set is now only 1 minute and 21 seconds.",
   "id": "569555bc2c7ec08e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for workers in range(1, 13):\n",
    "    time_dataloader(workers)"
   ],
   "id": "9dcf3710d36ae8c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "a) The number of workers has an impact on the runtime, though only a limited one: Initially, going from 1 worker to 2 workers reduced the runtime by 30 seconds, or almost a quarter of the initial runtime. The following modification of the workers does not have a visible effect anymore. The runtime stays constant after increasing the number further.",
   "id": "15aa250d3438e1be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "time_dataloader(batch_size=1024, num_workers=12)",
   "id": "c3ba7df477bc254a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "c) The maximum combination fluctuates highly. I could not figure out what causes the problem, yet. When everything is fine, the maximum seems to be about `batch_size` 4 if `num_workers` is 12 and `batch_size` 512 if `num_workers` is 1.",
   "id": "3fd6c14bf557060c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 2\n",
    "\n",
    "There does not seem to be an observable difference."
   ],
   "id": "665b49d11c25c4fe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Chapter 12\n",
    "\n",
    "### Exercise 1"
   ],
   "id": "c4239d96143bf1e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "5fc75ce514e7d9e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# More general implementation of f_score: Recall is considered beta times as important as precision\n",
    "def f_score(preds, labels, beta=1, classification_threshold=0.5):\n",
    "    # True positives: Elements identified as nodules that are actually nodules\n",
    "    # False positives: Elements identified as nodules that are not nodules\n",
    "    # True negatives: Elements not identified as nodules that are not nodules\n",
    "    # False negatives: Elements not identified as nodules that are nodules\n",
    "\n",
    "    pos_label_mask = labels > classification_threshold  # Actual nodules\n",
    "    pos_pred_mask = preds > classification_threshold    # Elements identified as nodules\n",
    "\n",
    "    neg_label_mask = ~pos_label_mask    # Actual non-nodules\n",
    "    neg_pred_mask = ~pos_pred_mask      # Elements identifies as non-nodules\n",
    "\n",
    "    pos_count = int(pos_label_mask.sum())   # Number of actual nodules\n",
    "    neg_count = int(neg_label_mask.sum())   # Number of actual non-nodules\n",
    "\n",
    "    true_neg_count = int((neg_label_mask & neg_pred_mask).sum())    # Number of non-nodules identified as such\n",
    "    true_pos_count = int((pos_label_mask & pos_pred_mask).sum())    # Number of nodules identified as such\n",
    "\n",
    "    false_pos_count = neg_count - true_neg_count    # Num. of samples identified as nodules, even though they are not nodules\n",
    "    false_neg_count = pos_count - true_pos_count    # Num. of samples identified as non-nodules, even though they are nodules\n",
    "\n",
    "    pos_pred_count = np.float32(true_pos_count + false_pos_count)\n",
    "    precision = true_pos_count / pos_pred_count if pos_pred_count > 0 else 0\n",
    "\n",
    "    act_pos_count = np.float32(true_pos_count + false_neg_count)\n",
    "    recall = true_pos_count / act_pos_count if act_pos_count > 0 else 0\n",
    "\n",
    "    denominator = ((beta ** 2) * precision) + recall\n",
    "    return (1 + beta ** 2) * (precision * recall) / denominator if denominator > 0 else 0.0"
   ],
   "id": "263b639174508dca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "b)\n",
    "To reiterate:\n",
    "\n",
    "- Recall: Number of samples correctly identified as positive against the number of actual positive samples\n",
    "- Precision: Number of samples correctly identified as positive against the number of samples identified as positive, whether wrong or right\n",
    "\n",
    "If we classify everything as positive, we have a lot of false positives, so precision will be very low. We will not have any false negatives, however, so recall will be high. If we classify everything as negative, both will be 0. In our case, we want to minimize false negatives, as we want to be really sure we miss no nodules, so we want to weigh recall higher than precision. In this case the F2 score is a better choice."
   ],
   "id": "3635793dddd1c78a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Exercise 2",
   "id": "680580bd11eb3298"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:00:44.760996Z",
     "start_time": "2025-08-07T13:00:44.681863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# Define Dataset\n",
    "weighted_ds = LunaDataset(\n",
    "    val_stride  = 10,\n",
    "    is_val_set  = True,\n",
    "    ratio_int   = 0,\n",
    ")\n",
    "\n",
    "# Get label counts\n",
    "candidate_info = weighted_ds.candidate_info_list\n",
    "\n",
    "label_counts = {}\n",
    "for candidate in candidate_info:\n",
    "    if candidate.isNodule_bool not in label_counts:\n",
    "        label_counts[candidate.isNodule_bool] = 0\n",
    "    label_counts[candidate.isNodule_bool] += 1\n",
    "\n",
    "# Use inverse of label count as weight for weighted sampler\n",
    "weights = [1 / label_counts[candidate.isNodule_bool] for candidate in candidate_info]\n",
    "weighted_sampler = WeightedRandomSampler(weights, len(weighted_ds))\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    weighted_ds,\n",
    "    sampler = weighted_sampler,\n",
    "    batch_size  = 1,\n",
    "    num_workers = 6,\n",
    "    pin_memory  = True\n",
    ")"
   ],
   "id": "f5cf9f5a320d51a9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 15:00:44,724 INFO     pid:3034 dsets:273:__init__ <dsets.LunaDataset object at 0x7f1b6d0009b0>: 55107 validation samples True\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T13:24:58.113311Z",
     "start_time": "2025-08-07T13:01:46.613594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_counts = {\n",
    "    'True': 0,\n",
    "    'False': 0\n",
    "}\n",
    "for batch in tqdm(train_dl):\n",
    "    if batch[1][0][0] == 1:\n",
    "        label_counts['False'] += 1\n",
    "    elif batch[1][0][1] == 1:\n",
    "        label_counts['True'] += 1\n",
    "\n",
    "label_counts"
   ],
   "id": "b2a548ee23f592b2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55107/55107 [23:11<00:00, 39.60it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'True': 27503, 'False': 27604}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "a) The candidate info list can be used to get the required information to construct the weights.\n",
    "\n",
    "b) Using the index seems to be more clean, as the code is not scattered around so much. In the codebase, this approach would create a mess in the functions creating the dataloaders."
   ],
   "id": "150677c9b8b95df7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 3\n",
    "\n",
    "a) Three different training and validation ratios were tested: 3:1, 2:1 and 1:1. Interestingly, using a uniform ratio was not the most effective with regard to the loss. For this metric, the middle ratio, 2:1, scored the best, whereas 3:1 was close behind. The same statement can be made for the f1 score, recall and precision.\n",
    "\n",
    "b) The application of the ratio as a function of the epoch has a positive effect on evaluation and train loss. The same statement can be made for the evaluation f1 score (as well as precision and recall), even though the values of these metrics of the train stage do not necessarily improve. Initially, these do also improve, but the higher the ratio gets, the worse they get. Nevertheless, as already mentioned, during evaluation, this function does increase the scores, indicating better generalization."
   ],
   "id": "322f6359a02a6f80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise 4\n",
    "\n",
    "a) The augmentation approaches noise, offset and scale can indeed be made more aggressive by changing their baseline values in `training.py`.\n",
    "\n",
    "b)\n",
    "\n",
    "c) There are a few augmentation tactics found, but only some of which are applicable here. I could find augmentation tactics specifically for text and audio data, which obviously is not the correct scope for this project. More suitable approaches I came across are the following:\n",
    "\n",
    "- Color space transformation: By randomly changing some the color channels, the contrast and brightness of the scans can be increased per slice. This does not seem like it would help here, but it could be considered.\n",
    "- Random erasing: This approach seems similar to noise. Random parts of each CT slice are deleted.\n",
    "- Salt and Pepper Noise: Whereas the current noise implementation uses a Gaussian distribution, some sources suggest to randomly insert black or white pixels, which imitate dead pixels or sensor dust. It does not seem like this would happen with CT scans, but it is definitely worth a try."
   ],
   "id": "d6aecbc615c91e77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# TODO: Finish other exercises",
   "id": "26744380094e4ddc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "da1e55769d824b81"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
