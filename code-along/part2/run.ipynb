{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T13:33:28.892178Z",
     "start_time": "2025-08-13T13:33:27.177126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils import importstr\n",
    "from utils import logging\n",
    "from utils import set_mode\n",
    "\n",
    "log = logging.getLogger('nb')\n",
    "set_mode('local')"
   ],
   "id": "4ed18d0a013a7e6e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T13:26:26.671034Z",
     "start_time": "2025-08-13T13:02:19.823939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from precache import LunaPrepCacheApp\n",
    "\n",
    "prep_cache = LunaPrepCacheApp(['--batch-size=32', '--subset-count=10', '--num-workers=0', '--dataset=seg'])\n",
    "prep_cache.main()"
   ],
   "id": "69e39b17d75bfcb0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 15:02:20,825 INFO     pid:25436 precache:053:main Starting LunaPrepCacheApp, Namespace(batch_size=32, num_workers=0, subset_count=10, dataset='seg')\n",
      "Subsets [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: 100%|██████████| 17216/17216 [23:59<00:00, 11.96it/s]  \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-13T13:33:28.905147Z",
     "start_time": "2025-08-13T13:33:28.900200Z"
    }
   },
   "source": [
    "def run(app, *argv):\n",
    "    argv = list(argv)\n",
    "    argv.insert(0, '--num_workers=12')\n",
    "    log.info(f'Running: {app}({argv!r}).main()')\n",
    "\n",
    "    app_cls = importstr(*app.rsplit('.', 1))\n",
    "    app_cls(argv).main()\n",
    "\n",
    "    log.info(f'Finished: {app}.{argv!r}')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T14:48:16.067498Z",
     "start_time": "2025-07-23T14:48:13.792596Z"
    }
   },
   "cell_type": "code",
   "source": "run('training.LunaTrainingApp', '--epochs=1')",
   "id": "18eea7c346f31fb9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 16:48:13,796 INFO     pid:5767 nb:004:run Running: training.LunaTrainingApp(['--num_workers=4', '--epochs=1']).main()\n",
      "usage: ipykernel_launcher.py [-h] [--num_workers NUM_WORKERS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --epochs=1\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[31mSystemExit\u001B[39m\u001B[31m:\u001B[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nico/miniconda3/envs/data-mining/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T13:36:20.931768Z",
     "start_time": "2025-08-13T13:33:32.298686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run(\n",
    "    'seg_training.SegmentationTrainingApp',\n",
    "    '--epochs=5',\n",
    "    '--batch-size=256',\n",
    "    '--no-require-on-disk',\n",
    "    '--augmented',\n",
    "    '--balance=2',\n",
    "    '--tb-prefix=seg',\n",
    "    f'test'\n",
    ")"
   ],
   "id": "8a994aaed14812f6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-13 15:33:32,300 INFO     pid:29677 nb:004:run Running: seg_training.SegmentationTrainingApp(['--num_workers=12', '--epochs=5', '--batch-size=256', '--no-require-on-disk', '--augmented', '--balance=2', '--tb-prefix=seg', 'test']).main()\n",
      "2025-08-13 15:33:33,036 INFO     pid:29677 training:179:init_tensorboard_writer Initializing tensorboard writer.\n",
      "2025-08-13 15:33:33,174 INFO     pid:29677 seg_training:050:init_model Using CUDA; 1 devices.\n",
      "2025-08-13 15:33:34,538 INFO     pid:29677 seg_training:154:main Starting ('SegmentationTrainingApp', Namespace(num_workers=12, batch_size=256, epochs=5, tb_prefix='seg', require_on_disk=False, balance=2, dynamic_ratio=False, augmented=True, augment_flip=False, augment_offset=False, augment_scale=False, augment_rotate=False, augment_noise=25, augment_mixup=False, no_reverse=True, norm='batch', comment='test'))\n",
      "2025-08-13 15:33:38,057 INFO     pid:29677 segmentation_ds:192:__init__ <segmentation_ds.TrainingLuna2dSegmentationDataset object at 0x7fa59c305850>: 799 train series, 8260 slices, 1070 nodules\n",
      "2025-08-13 15:33:38,130 INFO     pid:29677 segmentation_ds:192:__init__ <segmentation_ds.Luna2dSegmentationDataset object at 0x7fa591b05e20>: 88 eval series, 779 slices, 97 nodules\n",
      "2025-08-13 15:33:38,195 INFO     pid:29677 segmentation_ds:192:__init__ <segmentation_ds.Luna2dSegmentationDataset object at 0x7fa591af39b0>: 90 test series, 1029 slices, 113 nodules\n",
      "2025-08-13 15:33:38,196 INFO     pid:29677 seg_training:163:main Epoch 1 of 5, 1172/4 batches of size 256 \n",
      "E1 Training:  26%|██▌       | 302/1172 [02:41<07:46,  1.87it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mseg_training.SegmentationTrainingApp\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m--epochs=5\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m--batch-size=256\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m--no-require-on-disk\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m--augmented\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m--balance=2\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m--tb-prefix=seg\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mtest\u001B[39;49m\u001B[33;43m'\u001B[39;49m\n\u001B[32m     10\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 7\u001B[39m, in \u001B[36mrun\u001B[39m\u001B[34m(app, *argv)\u001B[39m\n\u001B[32m      4\u001B[39m log.info(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mRunning: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mapp\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00margv\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[33m).main()\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m      6\u001B[39m app_cls = importstr(*app.rsplit(\u001B[33m'\u001B[39m\u001B[33m.\u001B[39m\u001B[33m'\u001B[39m, \u001B[32m1\u001B[39m))\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m \u001B[43mapp_cls\u001B[49m\u001B[43m(\u001B[49m\u001B[43margv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m log.info(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mFinished: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mapp\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00margv\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[33m'\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/data-mining/code-along/part2/seg_training.py:168\u001B[39m, in \u001B[36mSegmentationTrainingApp.main\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    162\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m.cli_args.epochs):\n\u001B[32m    163\u001B[39m     log.info(\n\u001B[32m    164\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.cli_args.epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, \u001B[39m\u001B[33m'\u001B[39m +\n\u001B[32m    165\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(train_dl)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(val_dl)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m batches of size \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.cli_args.batch_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    166\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m168\u001B[39m     train_metrics = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mMETRICS_SIZE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    169\u001B[39m     \u001B[38;5;28mself\u001B[39m.log_metrics(epoch, \u001B[33m'\u001B[39m\u001B[33mtrain\u001B[39m\u001B[33m'\u001B[39m, train_metrics)\n\u001B[32m    171\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m epoch == \u001B[32m1\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m epoch % \u001B[38;5;28mself\u001B[39m.validation_cadence == \u001B[32m0\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/data-mining/code-along/part2/training.py:205\u001B[39m, in \u001B[36mTrainingApp.train\u001B[39m\u001B[34m(self, epoch, model, optimizer, dataloader, metrics_size)\u001B[39m\n\u001B[32m    202\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m batch_index, batch_tuple \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_progress):\n\u001B[32m    203\u001B[39m     optimizer.zero_grad()\n\u001B[32m--> \u001B[39m\u001B[32m205\u001B[39m     train_loss = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute_batch_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_tuple\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_metrics\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    207\u001B[39m     train_loss.backward()\n\u001B[32m    208\u001B[39m     optimizer.step()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/data-mining/code-along/part2/seg_training.py:124\u001B[39m, in \u001B[36mSegmentationTrainingApp.compute_batch_loss\u001B[39m\u001B[34m(self, batch_index, batch_tup, batch_size, metrics, classification_threshold)\u001B[39m\n\u001B[32m    119\u001B[39m labels = labels.to(\u001B[38;5;28mself\u001B[39m.device, non_blocking=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    121\u001B[39m \u001B[38;5;66;03m# if self.segmentation_model.training and self.augmentation_dict:\u001B[39;00m\n\u001B[32m    122\u001B[39m \u001B[38;5;66;03m#    inputs, labels = self.augmentation_model(inputs, labels)\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[38;5;66;03m# predictions = self.segmentation_model(inputs)\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m124\u001B[39m predictions, labels = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43maugmentation_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    126\u001B[39m dice_loss = \u001B[38;5;28mself\u001B[39m.dice_loss(predictions, labels)             \u001B[38;5;66;03m# Loss for the whole sample\u001B[39;00m\n\u001B[32m    127\u001B[39m fine_loss = \u001B[38;5;28mself\u001B[39m.dice_loss(predictions * labels, labels)    \u001B[38;5;66;03m# Loss only for the pixels, where labels is true\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/data-mining/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/data-mining/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/data-mining/code-along/part2/unet_model.py:28\u001B[39m, in \u001B[36mAugmentWrapper.forward\u001B[39m\u001B[34m(self, input_batch, labels, augment)\u001B[39m\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_batch, labels, augment=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m     27\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m augment:\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m         input_batch, labels = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43maugmentation_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     29\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.segmentation_model(input_batch), labels\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/data-mining/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/data-mining/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PycharmProjects/data-mining/code-along/part2/unet_model.py:59\u001B[39m, in \u001B[36mSegmentationAugmentation.forward\u001B[39m\u001B[34m(self, input_g, label)\u001B[39m\n\u001B[32m     57\u001B[39m transform_t = \u001B[38;5;28mself\u001B[39m._build_2d_transform_matrix()\n\u001B[32m     58\u001B[39m transform_t = transform_t.expand(input_g.shape[\u001B[32m0\u001B[39m], -\u001B[32m1\u001B[39m, -\u001B[32m1\u001B[39m)      \u001B[38;5;66;03m# Expand to all channels\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m transform_t = \u001B[43mtransform_t\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_g\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     61\u001B[39m affine_t = F.affine_grid(transform_t[:, :\u001B[32m2\u001B[39m], input_g.size(), align_corners=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m     63\u001B[39m \u001B[38;5;66;03m# The same transformation is applied to both the inputs and labels\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "78024b8bcc772dde"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
